{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers faiss-cpu langchain requests fitz numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nDF1OAm454FY",
        "outputId": "74e83bad-00e5-4772-b954-583da8d797cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Collecting fitz\n",
            "  Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl.metadata (816 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.24)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Collecting configobj (from fitz)\n",
            "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting configparser (from fitz)\n",
            "  Downloading configparser-7.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.10/dist-packages (from fitz) (0.22.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from fitz) (5.3.2)\n",
            "Collecting nipype (from fitz)\n",
            "  Downloading nipype-1.9.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz) (2.2.2)\n",
            "Collecting pyxnat (from fitz)\n",
            "  Downloading pyxnat-1.6.2-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2->fitz) (3.2.0)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (6.4.5)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (8.1.7)\n",
            "Collecting prov>=1.5.2 (from nipype->fitz)\n",
            "  Downloading prov-2.0.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Collecting rdflib>=5.0.0 (from nipype->fitz)\n",
            "  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting simplejson>=3.8.0 (from nipype->fitz)\n",
            "  Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting traits>=6.2 (from nipype->fitz)\n",
            "  Downloading traits-6.4.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting acres (from nipype->fitz)\n",
            "  Downloading acres-0.2.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting etelemetry>=0.3.1 (from nipype->fitz)\n",
            "  Downloading etelemetry-0.3.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting looseversion!=1.2 (from nipype->fitz)\n",
            "  Downloading looseversion-1.3.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting puremagic (from nipype->fitz)\n",
            "  Downloading puremagic-1.28-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2024.2)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (5.3.0)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Collecting ci-info>=0.2 (from etelemetry>=0.3.1->nipype->fitz)\n",
            "  Downloading ci_info-0.3.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain) (3.0.0)\n",
            "Collecting rdflib>=5.0.0 (from nipype->fitz)\n",
            "  Downloading rdflib-6.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.2->nipype->fitz) (1.17.0)\n",
            "Collecting isodate<0.7.0,>=0.6.0 (from rdflib>=5.0.0->nipype->fitz)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fitz-0.0.1.dev2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
            "Downloading configparser-7.1.0-py3-none-any.whl (17 kB)\n",
            "Downloading nipype-1.9.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyxnat-1.6.2-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading etelemetry-0.3.1-py3-none-any.whl (6.4 kB)\n",
            "Downloading looseversion-1.3.0-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading prov-2.0.1-py3-none-any.whl (421 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traits-6.4.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading acres-0.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading puremagic-1.28-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ci_info-0.3.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: puremagic, looseversion, traits, simplejson, isodate, faiss-cpu, configparser, configobj, ci-info, acres, rdflib, pyxnat, etelemetry, prov, nipype, fitz\n",
            "Successfully installed acres-0.2.0 ci-info-0.3.0 configobj-5.0.9 configparser-7.1.0 etelemetry-0.3.1 faiss-cpu-1.9.0.post1 fitz-0.0.1.dev2 isodate-0.6.1 looseversion-1.3.0 nipype-1.9.1 prov-2.0.1 puremagic-1.28 pyxnat-1.6.2 rdflib-6.3.2 simplejson-3.19.3 traits-6.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "backports"
                ]
              },
              "id": "16786886187a4e0db8935b4ab7648b89"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m48x73eN6dlB",
        "outputId": "15f5d4ed-99c8-47dc-da9a-88ca2f99d0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLkbPhE_52uB",
        "outputId": "bdde0ec0-01cc-47ce-fdf2-aa936130e668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Based on the provided context, here's the response to your query: From page 2 get the exact unemployment information based on type of degree input\n",
            "\n",
            "Context:\n",
            "Tables, Charts, and Graphs with Examples from History, Economics, Education, Psychology, Urban Affairs and Everyday Life REVISED: MICHAEL LOLKUS 2018 Tables, Charts, and Graphs Basics We use charts and graphs to visualize data. This data can either be generated data, data gathered from an experiment, or data collected from some source. A picture tells a thousand words so it is not a surprise that many people use charts and graphs when explaining data. Types of Visual Representations of Data Table of Yearly U.S. GDP by Industry (in millions of dollars) Year 2010 2011 2012 2013 2014 2015 All Industries 26093515 27535971 28663246 29601191 30895407 31397023 Manufacturing 4992521 5581942 5841608 5953299 6047477 5829554 Finance, Insurance, Real Estate, Rental, Leasing 4522451 4618678 4797313 5031881 5339678 5597018 Arts, Entertainment, Recreation, Accommodation, and Food Service 964032 1015238 1076249 1120496 1189646 1283813 Other 15614511 16320113 16948076 17495515 18318606 18686638 Source: U.S. Bureau of Labor Statistics 19% 18% 4% 59% 2015 U.S. GDP (in millions of dollars) Manufacturing Finance, insurance, real estate, rental, and leasing Arts, entertainment, recreation, accommodation, and food services Other • The chart below is called a pie chart. It shows what percent “of the pie” a particular category occupies out of the whole. • If total GDP in 2015 is the entire pie, then manufacturing makes up 19% of that pie and finance makes up 18%. Notice that visually speaking, since 19% and 18% are so close to each other in value, their respective slices of the pie are similarly sized. Pie charts can be misleading when the slices do not correspond with the percent contribution to the whole pie. Notice the pie chart below is not very intuitive. Example from Everyday Life 19% 10% 15% 5% 26% 25% Family Budget of $31,000 Other Recreation Transportation Clothing housing Food The following chart shows how a family spends its yearly income of $31,000. How much money does this family spend on transportation? Solution The chart indicates that 15% of the income is spent on transportation. We must answer the question: 15% of $31,000 is what? Writing as an equation and solving, we get n = 0.15 x 31,000 = 4650 So the family spends $4650 on transportation yearly. 0 5 10 15 20 25 30 35 All industries Manufacturing Finance, insurance, real estate, rental, and leasing Arts, entertainment, recreation, accommodation, and food services Other Dollars 2015 GDP (in trillions of dollars) • The graph below is called a bar graph. • It shows each of the variables independent of each other, each with its own bar. • 2015 GDP for all industries was $31.397023; looking at the graph, the bar for all industries is just above $30. • One is still be able compare each variable with the other by comparing bars. • The graph below is called a line graph. It shows how a variable evolves with respect to another variable. In the line graph below, we show how GDP has evolved by year. 0 5 10 15 20 25 30 35\n",
            "1947 1950 1953 1956 1959 1962 1965 1968 1971 1974 1977 1980 1983 1986 1989 1992 1995 1998 2001 2004 2007 2010 2013 Dollars Year Yearly Total GDP (in trillions of dollars) Yearly Total GDP When to use a Line Graph, Pie Chart, or Bar Graph? We use the pie chart here to compare parts of a whole. In our example, we compared components of US GDP. The line chart is useful when you want to show how a variable changes over time. For our purposes, we used it show how GDP changed over time. Bar graphs are good for comparing different groups of variables. We used it to compare different components of US GDP. We did the same with the pie chart; depending on your purposes you may choose to use a pie chart or a bar graph. x y 0 0 1 3 2 6 3 9 4 12 5 15 6 18 7 21 8 24 • If given a table of data, we should be able to plot it. Below is some sample data; plot the data with x on the x-axis and y on the y-axis. 0 5 10 15 20 25 30 0 1 2 3 4 5 6 7 8 • Below is a plot of the data on the table from the previous slide. Notice that this plot is a straight line meaning that a linear equation must have generated this data. • What if the data is not generated by a linear equation? We can fit the data using a linear regression and use that line as an approximation to the data. Regressions are beyond the scope of this workshop. Example from Urban Affairs What kind of bar graph is this? Whose life expectancy has changed the most since 1925? In 1925, about how much longer was a woman expected to live than a man? Example from History In what years were the affiliations for Republicans and Independents the same? During what time period did the party affiliations have the most change? Example from Education What percent of the total class received grades of 72 or 77? Which grade showed the largest difference between males and females? Example from Psychology What do you notice is different in this graph than the others reviewed so far?\n",
            "1947 1950 1953 1956 1959 1962 1965 1968 1971 1974 1977 1980 1983 1986 1989 1992 1995 1998 2001 2004 2007 2010 2013 Dollars Year Yearly Total GDP (in trillions of dollars) Yearly Total GDP When to use a Line Graph, Pie Chart, or Bar Graph? We use the pie chart here to compare parts of a whole. In our example, we compared components of US GDP. The line chart is useful when you want to show how a variable changes over time. For our purposes, we used it show how GDP changed over time. Bar graphs are good for comparing different groups of variables. We used it to compare different components of US GDP. We did the same with the pie chart; depending on your purposes you may choose to use a pie chart or a bar graph. x y 0 0 1 3 2 6 3 9 4 12 5 15 6 18 7 21 8 24 • If given a table of data, we should be able to plot it. Below is some sample data; plot the data with x on the x-axis and y on the y-axis. 0 5 10 15 20 25 30 0 1 2 3 4 5 6 7 8 • Below is a plot of the data on the table from the previous slide. Notice that this plot is a straight line meaning that a linear equation must have generated this data. • What if the data is not generated by a linear equation? We can fit the data using a linear regression and use that line as an approximation to the data. Regressions are beyond the scope of this workshop. Example from Urban Affairs What kind of bar graph is this? Whose life expectancy has changed the most since 1925? In 1925, about how much longer was a woman expected to live than a man? Example from History In what years were the affiliations for Republicans and Independents the same? During what time period did the party affiliations have the most change? Example from Education What percent of the total class received grades of 72 or 77? Which grade showed the largest difference between males and females? Example from Psychology What do you notice is different in this graph than the others reviewed so far?\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import fitz  # PyMuPDF\n",
        "import requests\n",
        "import io\n",
        "import time\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# Initialize the SentenceTransformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # You can change to another model from Sentence Transformers if needed\n",
        "\n",
        "# Function to extract text from a PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    if pdf_path.startswith(\"http\"):  # Handle URLs\n",
        "        response = requests.get(pdf_path)\n",
        "        response.raise_for_status()  # Raise an exception if download fails\n",
        "        pdf_data = io.BytesIO(response.content)\n",
        "        doc = fitz.open(stream=pdf_data, filetype=\"pdf\")  # Open from bytes\n",
        "    else:\n",
        "        doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text(\"text\")\n",
        "    return text\n",
        "\n",
        "# Function to chunk text into smaller pieces for embeddings\n",
        "def chunk_text(text, chunk_size=500):\n",
        "    words = text.split()\n",
        "    chunks = [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "# Function to create embeddings for chunks\n",
        "def create_embeddings(chunks, embeddings_cache_path=\"embeddings.pkl\"):\n",
        "    if os.path.exists(embeddings_cache_path):\n",
        "        with open(embeddings_cache_path, \"rb\") as f:\n",
        "            embeddings = pickle.load(f)\n",
        "        return embeddings\n",
        "\n",
        "    embeddings = model.encode(chunks)  # Generate embeddings using SentenceTransformers model\n",
        "\n",
        "    # Cache embeddings to a file\n",
        "    with open(embeddings_cache_path, \"wb\") as f:\n",
        "        pickle.dump(embeddings, f)\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "# Function to store embeddings in FAISS\n",
        "def store_embeddings_in_faiss(embeddings):\n",
        "    embedding_dim = len(embeddings[0])\n",
        "    index = faiss.IndexFlatL2(embedding_dim)  # L2 similarity\n",
        "    np_embeddings = np.array(embeddings, dtype='float32')\n",
        "    index.add(np_embeddings)\n",
        "    return index\n",
        "\n",
        "# Function to perform similarity search on embeddings\n",
        "def search_embeddings(query, index, chunks, top_k=3):\n",
        "    query_embedding = model.encode([query])  # Generate embedding for the query using SentenceTransformers\n",
        "\n",
        "    # Search the FAISS index\n",
        "    query_vector = np.array(query_embedding, dtype='float32').reshape(1, -1)\n",
        "    distances, indices = index.search(query_vector, top_k)\n",
        "\n",
        "    # Fetch the most relevant chunks\n",
        "    relevant_chunks = [chunks[i] for i in indices[0]]\n",
        "    return relevant_chunks\n",
        "\n",
        "# Function to generate a response (simplified here without LangChain)\n",
        "def generate_response(user_query, relevant_chunks):\n",
        "    context = \"\\n\".join(relevant_chunks)  # Combine the relevant chunks\n",
        "    response = f\"Based on the provided context, here's the response to your query: {user_query}\\n\\nContext:\\n{context}\"\n",
        "    return response\n",
        "\n",
        "# Main pipeline function\n",
        "def run_pipeline(pdf_path, user_query):\n",
        "    # Step 1: Extract and chunk text\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    chunks = chunk_text(text)\n",
        "\n",
        "    # Step 2: Create and store embeddings\n",
        "    embeddings = create_embeddings(chunks)\n",
        "    index = store_embeddings_in_faiss(embeddings)\n",
        "\n",
        "    # Step 3: Retrieve relevant chunks for the query\n",
        "    relevant_chunks = search_embeddings(user_query, index, chunks)\n",
        "\n",
        "    # Step 4: Generate response\n",
        "    response = generate_response(user_query, relevant_chunks)\n",
        "    return response\n",
        "\n",
        "# Running the pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    # Path to the PDF file you want to process\n",
        "    pdf_path = \"https://www.hunter.cuny.edu/dolciani/pdf_files/workshop-materials/mmc-presentations/tables-charts-and-graphs-with-examples-from.pdf\"  # Replace with the actual path to your PDF\n",
        "\n",
        "    # The query that you want to ask based on the content of the PDF\n",
        "    user_query = \"From page 2 get the exact unemployment information based on type of degree input\"  # Replace with your own query\n",
        "\n",
        "    # Run the pipeline\n",
        "    response = run_pipeline(pdf_path, user_query)\n",
        "\n",
        "    # Print the response\n",
        "    print(\"Response:\", response)\n"
      ]
    }
  ]
}